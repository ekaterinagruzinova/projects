{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "054951d9",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc60e3",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4a0ab",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Нужно построить модель со значением метрики качества *F1* не меньше 0.75. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57315c68",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccea653",
   "metadata": {},
   "source": [
    "Задача проекта - нахождение моделью токсичных комментариев. Для этого мы должны обучить модель, которая сможет классифицировать - негативную или позитивную каннотацию имеет текст комментария. Мы подготовим данные (загрузим их, ознакомимся с ними, проведём нормализацию текстов - токенизацию, лемматизацию, уберём стоп-слова и пунктуацию), обучим несколько моделей и выберем лучшую. Для проверки эффективности моделей мы будем использовать метрику f1. Выбирать модель будем исходя из значения метрики f1 на валидационной выборке. Затем лучшую модель проверим на тестовой выборке. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd530a3d",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a0210",
   "metadata": {},
   "source": [
    "Произведём необходимые \"импорты\" и загрузим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "295397c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "185170cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               text  toxic\n",
      "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
      "1           1  D'aww! He matches this background colour I'm s...      0\n",
      "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
      "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4           4  You, sir, are my hero. Any chance you remember...      0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/p_kok/Downloads/toxic_comments.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "586bd892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09587e74",
   "metadata": {},
   "source": [
    "Пропусков нет, типы данных корректные. Проверим, все ли данные размечены адекватно: посмотрим, какие значения есть в столбце toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3f38c251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d965e",
   "metadata": {},
   "source": [
    "Всё в порядке, в столбце toxic только 0 и 1 (комментарий токсичен или нетоксичен). Переходим к подготовке данных. Первый этап - лемматизация и удаление стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ac30163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 159292/159292 [2:05:00<00:00, 21.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#ВНИМАНИЕ!!! лемматизация в этой ячейке идёт около 2 часов\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tqdm.pandas()\n",
    "df['lemm'] = df['text'].progress_apply(lambda text: \" \".join(token.lemma_ for token in nlp(text) if not token.is_stop)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fae5a",
   "metadata": {},
   "source": [
    "Посмотрим на результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6939adfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation \\n edit username Hardcore Metallic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww ! match background colour seemingly stuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , try edit war . guy constantly remove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\" \\n \\n real suggestion improvement - wonder s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>, sir , hero . chance remember page ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\" : : : : : second time ask , view completely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ashamed \\n\\n horrible thing talk page .   128....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer \\n\\n Umm , s actual article prostituti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>look like actually speedy version delete look .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>\" \\n ... think understand .   come idea bad ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1                1  D'aww! He matches this background colour I'm s...      0   \n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4                4  You, sir, are my hero. Any chance you remember...      0   \n",
       "...            ...                                                ...    ...   \n",
       "159287      159446  \":::::And for the second time of asking, when ...      0   \n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159290      159449  And it looks like it was actually you who put ...      0   \n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                     lemm  \n",
       "0       explanation \\n edit username Hardcore Metallic...  \n",
       "1       d'aww ! match background colour seemingly stuc...  \n",
       "2       hey man , try edit war . guy constantly remove...  \n",
       "3       \" \\n \\n real suggestion improvement - wonder s...  \n",
       "4                   , sir , hero . chance remember page ?  \n",
       "...                                                   ...  \n",
       "159287  \" : : : : : second time ask , view completely ...  \n",
       "159288  ashamed \\n\\n horrible thing talk page .   128....  \n",
       "159289  Spitzer \\n\\n Umm , s actual article prostituti...  \n",
       "159290    look like actually speedy version delete look .  \n",
       "159291  \" \\n ... think understand .   come idea bad ri...  \n",
       "\n",
       "[159292 rows x 4 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447976c3",
   "metadata": {},
   "source": [
    "Следующий этап - удаление пунктуации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3c0df56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#время радоты ячейки около 12 минут\n",
    "\n",
    "for i in range(len(df['lemm'])):\n",
    "    df['lemm'][i] = re.sub(r'[^\\w\\s]','', df['lemm'][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5679b921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation \\n edit username Hardcore Metallic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>daww  match background colour seemingly stuck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man  try edit war  guy constantly remove r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n \\n real suggestion improvement  wonder sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir  hero  chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>second time ask  view completely contrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ashamed \\n\\n horrible thing talk page    12861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer \\n\\n Umm  s actual article prostitutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>look like actually speedy version delete look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n  think understand    come idea bad right a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1                1  D'aww! He matches this background colour I'm s...      0   \n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4                4  You, sir, are my hero. Any chance you remember...      0   \n",
       "...            ...                                                ...    ...   \n",
       "159287      159446  \":::::And for the second time of asking, when ...      0   \n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159290      159449  And it looks like it was actually you who put ...      0   \n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                     lemm  \n",
       "0       explanation \\n edit username Hardcore Metallic...  \n",
       "1       daww  match background colour seemingly stuck ...  \n",
       "2       hey man  try edit war  guy constantly remove r...  \n",
       "3        \\n \\n real suggestion improvement  wonder sec...  \n",
       "4                        sir  hero  chance remember page   \n",
       "...                                                   ...  \n",
       "159287        second time ask  view completely contrad...  \n",
       "159288  ashamed \\n\\n horrible thing talk page    12861...  \n",
       "159289  Spitzer \\n\\n Umm  s actual article prostitutio...  \n",
       "159290     look like actually speedy version delete look   \n",
       "159291   \\n  think understand    come idea bad right a...  \n",
       "\n",
       "[159292 rows x 4 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9edb25d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны корректно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c1f50",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc4083",
   "metadata": {},
   "source": [
    "Данные подготовлены, переходим к обучение моделей. Сначала разделим датасет на обучающую, валидационную и тестовую выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c0941d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid_test = train_test_split(df, train_size=0.81, random_state=12345, stratify=df['toxic'])\n",
    "valid, test = train_test_split(valid_test, train_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2ef6d",
   "metadata": {},
   "source": [
    "Проверим, корректно ли прошло разделение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "997ec004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15133, 4) Test: 10%\n",
      "(15133, 4) Valid: 10%\n",
      "(129026, 4) Train: 81%\n"
     ]
    }
   ],
   "source": [
    "print(test.shape, 'Test: {:.0%}'.format(len(test)/len(df)))\n",
    "print(valid.shape, 'Valid: {:.0%}'.format(len(valid)/len(df)))\n",
    "print(train.shape, 'Train: {:.0%}'.format(len(train)/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d74454",
   "metadata": {},
   "source": [
    "Рассчитаем tf-idf для всех выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1314c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer().fit(train['lemm'].values)\n",
    "tf_idf_train = vectorizer.transform(train['lemm'].values)\n",
    "tf_idf_valid = vectorizer.transform(valid['lemm'].values)\n",
    "tf_idf_test = vectorizer.transform(test['lemm'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea1a55",
   "metadata": {},
   "source": [
    "Определим признаки и целевой признак для всех выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2ed193f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = tf_idf_train\n",
    "target_train = train['toxic']\n",
    "\n",
    "features_valid = tf_idf_valid\n",
    "target_valid = valid['toxic']\n",
    "\n",
    "features_test = tf_idf_test\n",
    "target_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395c2b5",
   "metadata": {},
   "source": [
    "Обучим модель дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "72490aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для решающего дерева: 0.5653742110009017\n"
     ]
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=12345, max_depth=7)\n",
    "model_tree.fit(features_train, target_train) \n",
    "predicted = model_tree.predict(features_valid)\n",
    "f1_tree = f1_score(target_valid, predicted)\n",
    "print(\"f1 для решающего дерева:\", f1_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35027c30",
   "metadata": {},
   "source": [
    "Значение метрики f1 недостаточно высоко. Попробуем подобрать более подходящую глубину дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7dd8cb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.3106904231625835\n",
      "max_depth = 2 : 0.38165524512387977\n",
      "max_depth = 3 : 0.43243243243243246\n",
      "max_depth = 4 : 0.4742574257425743\n",
      "max_depth = 5 : 0.502906976744186\n",
      "max_depth = 6 : 0.542230517965469\n",
      "max_depth = 7 : 0.5653742110009017\n",
      "max_depth = 8 : 0.577636939791761\n",
      "max_depth = 9 : 0.5972651080723422\n",
      "max_depth = 10 : 0.6073943661971831\n",
      "max_depth = 11 : 0.6135871916919082\n",
      "max_depth = 12 : 0.6217034154777346\n",
      "max_depth = 13 : 0.6264020707506471\n",
      "max_depth = 14 : 0.6335190741534505\n",
      "max_depth = 15 : 0.6308551783412119\n",
      "max_depth = 16 : 0.6420787929589271\n",
      "max_depth = 17 : 0.6484670306593868\n",
      "max_depth = 18 : 0.6547717842323652\n",
      "max_depth = 19 : 0.6595306710580485\n",
      "max_depth = 20 : 0.6620123203285421\n",
      "max_depth = 21 : 0.6729124236252545\n",
      "max_depth = 22 : 0.6742671009771988\n",
      "max_depth = 23 : 0.6804374240583233\n",
      "max_depth = 24 : 0.68261045804621\n",
      "max_depth = 25 : 0.6807473598700243\n",
      "max_depth = 26 : 0.6879289463060153\n",
      "max_depth = 27 : 0.690850463522773\n",
      "max_depth = 28 : 0.6877022653721683\n",
      "max_depth = 29 : 0.6839126919967664\n",
      "max_depth = 30 : 0.6854158296504621\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15564/3573351484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12345\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \"\"\"\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for depth in range(1, 30):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    predicted = model_tree.predict(features_valid)\n",
    "    result = f1_score(target_valid, predicted)\n",
    "    print('max_depth =', depth, ':', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e709f",
   "metadata": {},
   "source": [
    "Лучшая глубина - 27. Но такого значения метрики f1 недостаточно. Обучим модель случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f18fd039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE для случайного леса: 0.0013218770654329147\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(max_depth=27, n_estimators=100, min_samples_leaf= 15, random_state=12345)\n",
    "model_forest.fit(features_train, target_train) \n",
    "predicted = model_forest.predict(features_valid)\n",
    "f1_forest = f1_score(target_valid, predicted)\n",
    "print(\"RMSE для случайного леса:\", f1_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051fc26",
   "metadata": {},
   "source": [
    "Обучим модель логистической регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "dfb19a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7498033044846579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C=1.0, penalty='l2', random_state = 12345, max_iter = 70)\n",
    "model_lr.fit(features_train, target_train)\n",
    "prediction = model_lr.predict(features_valid)\n",
    "f1 = f1_score(target_valid, prediction)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f900d0",
   "metadata": {},
   "source": [
    "Значение метрики f1 близко к искомому, попробуем подобрать параметры, чтобы увеличить значение метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ee0312a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1 : 0.7491138243402914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 2 : 0.7809885931558935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 3 : 0.7876738068395341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 4 : 0.792859799181852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 5 : 0.794074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 6 : 0.7940850277264324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 7 : 0.7939661515820456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 8 : 0.7916207276736494\n",
      "C = 9 : 0.7921081476068688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for par in range(1, 10):\n",
    "    model_lr = LogisticRegression(C=par, penalty='l2', random_state = 12345, max_iter = 100)\n",
    "    model_lr.fit(features_train, target_train)\n",
    "    prediction = model_lr.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, prediction)\n",
    "    print('C =', par, ':', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b073a6",
   "metadata": {},
   "source": [
    "Логистическая регрессия показала хороший результат с параметром C = 6, его и выберем для проверки на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5e37960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7940850277264324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C=6.0, penalty='l2', random_state = 12345, max_iter = 100)\n",
    "model_lr.fit(features_train, target_train)\n",
    "prediction = model_lr.predict(features_valid)\n",
    "f1 = f1_score(target_valid, prediction)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e1a5d",
   "metadata": {},
   "source": [
    "Проверим логистическую регрессию с выбранными параметрами на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "268b78bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702312138728323\n"
     ]
    }
   ],
   "source": [
    "prediction = model_lr.predict(features_test)\n",
    "f1 = f1_score(target_test, prediction)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50f835",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248c49d",
   "metadata": {},
   "source": [
    "Для решения задачи классификации комментария как токсичного или нетоксичного мы подготовили данные (провели лемматизацию, избавились от стоп-слов и пунктуации) и обучили несколько моделей. Лучший результат показала модель логистической регрессии, которую мы и рекомендуем для решения данной задачи. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
